{
  "model": "../models/meta-llama/Llama-2-7b-hf",
  "disable_log_requests": "true",
  "gpu_memory_utilization": 0.9,
  "enforce_eager": "true",
  "max_model_len": "4096"
}