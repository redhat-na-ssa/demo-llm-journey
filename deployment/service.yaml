--- 
apiVersion: v1
kind: Service
metadata:
  labels:
    app: triton-vllm-inference-server
    app.kubernetes.io/component: triton-vllm-inference-server
    app.kubernetes.io/instance: triton-vllm-inference-server
    app.kubernetes.io/name: triton-vllm-inference-server
    app.kubernetes.io/part-of: triton-vllm-inference-server-app
    app.openshift.io/runtime-version: latest
  name: triton-vllm-inference-server
spec:
  ports:
  - name: 8000-tcp
    port: 8000
    protocol: TCP
    targetPort: 8000
  - name: 8001-tcp
    port: 8001
    protocol: TCP
    targetPort: 8001
  - name: 8002-tcp
    port: 8002
    protocol: TCP
    targetPort: 8002
  selector:
    app: triton-vllm-inference-server
    deployment: triton-vllm-inference-server
  type: ClusterIP
