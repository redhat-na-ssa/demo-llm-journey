# demo-llm-journey

Demo LLM things

## Quick Start

```sh
until oc apply -k bootstrap; do : ; done
```

## Related Links

- https://github.com/redhat-na-ssa/demo-ai-gitops-catalog

### Triton Inference Server Wrapper

This project contains a container wrapper around the NVIDIA Triton Inference Server for serving LLMs:

- https://github.com/carlmes/triton-vllm-inference-server
